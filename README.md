# Цифровая солидарность в условиях гуманитарного кризиса | Digital Solidarity in Humanitarian Crisis

Анализ предложений бесплатного жилья для внутренне перемещенных лиц на платформе Avito

## Описание проекта

Данный проект исследует проявления гражданской солидарности в России через анализ предложений бесплатного временного жилья на платформе Avito для жителей Курской области, вынужденно покинувших свои дома в августе 2024 года.

Проект включает полный цикл работы с данными: от автоматизированного сбора информации (web scraping) до детального анализа и визуализации.

### Основной вопрос исследования:

**Как проявляется цифровая солидарность граждан в условиях гуманитарного кризиса?**

### Дополнительные вопросы:

- **География солидарности:** Какие регионы России наиболее активно предлагают помощь?
- **Условия помощи:** На какие сроки люди готовы предоставлять жилье бесплатно?
- **Характеристики жилья:** Какие типы жилья предлагаются (квартиры, комнаты, дома)?
- **Ценовые характеристики:** Какова обычная рыночная стоимость предлагаемого жилья?

## Данные

### Источник данных:
- Платформа: **Avito.ru**
- Фильтр: **#яПомогаю** (объявления для вынужденно покинувших свои дома)
- Категории: квартиры, комнаты, дома (аренда на длительный срок)
- Период сбора: актуальные объявления на момент декабря 2025

### Размер датасета:
- Собрано объявлений: ~150+ (3 страницы по каждой категории)
- Файлы:
  - `raw_data.csv` — сырые данные после парсинга
  - `preprocessed_data.csv` — очищенные данные для анализа

### Переменные датасета:

**Параметры:**
- URL объявления
- Заголовок
- Цена
- Количество комнат
- Площадь
- Адрес
- "Вынужденно покинувшим свои дома" - на какой срок арендодатели готовы бесплатно поселить вынужденно покинувших свои дома
- Время публикации
- Дата сбора данных
## Технологии и инструменты

### Парсинг данных:
- **Python 3.9+**
- **Selenium** — автоматизация веб-браузера
- **WebDriver Manager** — управление драйверами
- **BeautifulSoup** / **lxml** — парсинг HTML
- **Pandas** — обработка данных
- **tqdm** — прогресс-бары

### Анализ данных:
- **Pandas** — очистка и трансформация данных
- **NumPy** — численные вычисления
- **Matplotlib** / **Seaborn** — визуализация
- **Regular Expressions** — обработка текста

## Методология

### 1. Сбор данных (Data Collection)

**Технология:** Selenium WebDriver для динамического контента

**Процесс:**
1. Настройка headless-браузера Chrome
2. Парсинг 3 категорий объявлений (квартиры, комнаты, дома)
3. Извлечение данных с каждой страницы
4. Обработка пагинации и динамической подгрузки
5. Сохранение в `raw_data.csv`

**Особенности:**
- Случайные задержки между запросами (антибан)
- Обработка исключений и таймаутов
- Логирование процесса сбора

### 2. Предобработка данных (Data Preparation)

**Этапы очистки:**
1. Удаление дубликатов по URL
2. Обработка пропущенных значений
3. Парсинг и стандартизация адресов
4. Извлечение города и региона
5. Нормализация числовых значений
6. Преобразование типов данных

**Результат:** `preprocessed_data.csv`

### 3. Исследовательский анализ данных (EDA)

**Анализируемые аспекты:**

**География:**
- Распределение предложений по регионам России
- TOP-10 городов по количеству объявлений
- Картографирование солидарности

**Характеристики жилья:**
- Распределение по типам (квартиры/комнаты/дома)
- Площадь предлагаемого жилья
- Количество комнат

**Экономический контекст:**
- Рыночная стоимость бесплатного жилья
- Оценка масштаба финансовой помощи

**Временные паттерны:**
- Динамика публикации объявлений
- Анализ активности по дням/неделям

## Структура проекта

```
avito-solidarity-analysis/
├── Data_collection.ipynb           # Jupyter Notebook: парсинг данных
├── Data_preparation_and_analysis.ipynb  # Jupyter Notebook: очистка и анализ
├── raw_data.csv                    # Сырые данные после парсинга
├── preprocessed_data.csv           # Очищенные данные
├── requirements.txt                # Зависимости проекта
├── README.md                       # Документация проекта
└── .gitignore                      # Игнорируемые файлы
```

## Как запустить проект

### Требования:

```bash
pip install -r requirements.txt
```

### Запуск:

1. **Клонируйте репозиторий:**
```bash
git clone https://github.com/[ваш-username]/avito-solidarity-analysis.git
cd avito-solidarity-analysis
```

2. **Установите зависимости:**
```bash
pip install -r requirements.txt
```

3. **Запустите ноутбуки:**

**Сбор данных (опционально — данные уже собраны):**
```bash
jupyter notebook Data_collection.ipynb
```

**Анализ данных:**
```bash
jupyter notebook Data_preparation_and_analysis.ipynb
```

> **Важно:** Для запуска парсинга необходим Chrome/Chromium браузер. WebDriver загрузится автоматически.

## Навыки, продемонстрированные в проекте

### Сбор данных:
- Web Scraping (Selenium, BeautifulSoup)
- Работа с динамическим контентом
- Обработка пагинации
- Антибан-стратегии (задержки, User-Agent)
- Обработка исключений и ошибок

### Обработка данных:
- Очистка и нормализация данных
- Regular Expressions для парсинга текста
- Обработка пропущенных значений
- Feature Engineering (извлечение городов, регионов)

### Анализ данных:
- Exploratory Data Analysis (EDA)
- Визуализация данных (Matplotlib, Seaborn)
- Статистический анализ
- Работа с географическими данными

### Социальные исследования:
- Формулирование исследовательских вопросов
- Контекстуализация данных
- Интерпретация социальных явлений

## Лицензия

MIT License - проект доступен для использования и модификации.
